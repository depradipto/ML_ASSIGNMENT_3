{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is Simple Linear Regression0?\n",
        "- Simple Linear Regression is a statistical method used to model the\n",
        " relationship between two variables by fitting a linear equation to observed data. One variable is independent (X) and the other is dependent (Y).\n",
        "\n",
        "\n",
        "2. What are the key assumptions of Simple Linear Regression?\n",
        " - Linearity: The relationship between X and Y is linear.\n",
        "\n",
        " Independence: Observations are independent of each other.\n",
        "\n",
        " Homoscedasticity: Constant variance of residuals.\n",
        "\n",
        " Normality: Residuals are normally distributed.\n",
        "\n",
        "3. What does the coefficient m represent in the equation Y=mX+c?\n",
        " - m is the slope, indicating how much Y changes for a one-unit change in X.\n",
        "\n",
        "\n",
        "4. What does the intercept c represent in the equation Y=mX+c?\n",
        " - c is the Y-intercept, the predicted value of Y when X = 0.\n",
        "\n",
        "\n",
        "5. How do we calculate the slope m in Simple Linear Regression?\n",
        " - m = Σ[(xi - x̄)(yi - ȳ)] / Σ(xi - x̄)²\n",
        "\n",
        "6. What is the purpose of the least squares method in Simple Linear Regression?\n",
        " - To minimize the sum of the squares of the residuals (differences between observed and predicted values).\n",
        "\n",
        "\n",
        "7. How is the coefficient of determination (R²) interpreted in Simple Linear\n",
        "Regression?\n",
        " - R² represents the proportion of the variance in the dependent variable that is predictable from the independent variable (ranges from 0 to 1).\n",
        "\n",
        "8. What is Multiple Linear Regression?\n",
        " - A regression model that predicts a dependent variable using two or more independent variables.\n",
        "\n",
        "9. What is the main difference between Simple and Multiple Linear Regression ?\n",
        " - Simple: One independent variable.\n",
        "\n",
        " Multiple: Two or more independent variables.\n",
        "\n",
        "10. What are the key assumptions of Multiple Linear Regression?\n",
        " - Linearity\n",
        "\n",
        " Independence\n",
        "\n",
        " Homoscedasticity\n",
        "\n",
        " Normality of residuals\n",
        "\n",
        " No multicollinearity (independent variables aren't too correlated)\n",
        "\n",
        "11. What is heteroscedasticity, and how does it affect the results of a\n",
        "Multiple Linear Regression model?\n",
        " - Heteroscedasticity refers to non-constant variance of residuals. It can lead to inefficient estimates and misleading inference (e.g., incorrect p-values).\n",
        "\n",
        "12. How can you improve a Multiple Linear Regression model with high\n",
        "multicollinearity?\n",
        " - Remove or combine correlated predictors\n",
        "\n",
        " Use Principal Component Analysis (PCA)\n",
        "\n",
        " Apply Ridge or Lasso regression\n",
        "\n",
        "\n",
        "13. What are some common techniques for transforming categorical variables for\n",
        "use in regression models?\n",
        " - One-Hot Encoding\n",
        "\n",
        " Label Encoding\n",
        "\n",
        " Ordinal Encoding\n",
        "\n",
        "14. What is the role of interaction terms in Multiple Linear Regression?\n",
        " - Interaction terms allow the effect of one predictor to depend on the level of another, capturing more complex relationships.\n",
        "\n",
        "15. How can the interpretation of intercept differ between Simple and Multiple\n",
        "Linear Regression?\n",
        " - In Simple Regression, the intercept is the value of Y when X=0.\n",
        " In Multiple Regression, it's the value of Y when all Xs are 0, which may not be meaningful.\n",
        "\n",
        "16. What is the significance of the slope in regression analysis, and how does\n",
        "it affect predictions?\n",
        " - The slope indicates the change in the dependent variable for a one-unit change in the independent variable, impacting the direction and steepness of the prediction line.\n",
        "\n",
        "17. What are the limitations of using R² as a sole measure of model performance?\n",
        " - Doesn’t indicate if the model is biased.\n",
        "\n",
        " Can be artificially high with more predictors.\n",
        "\n",
        " Doesn’t measure predictive accuracy on new data.\n",
        "\n",
        "\n",
        "18. How would you interpret a large standard error for a regression coefficient?\n",
        " - It suggests low precision, implying the coefficient estimate may not be reliable or statistically significant.\n",
        "\n",
        "19. What is polynomial regression When is polynomial regression used?\n",
        " - Polynomial regression fits a non-linear relationship using a polynomial equation. It is used when data shows curvature that a straight line cannot fit well.\n",
        "\n",
        "20. How does the intercept in a regression model provide context for the relationship between variables?\n",
        " - It represents the expected value of the dependent variable when all independent variables are zero, giving a baseline or starting value.\n",
        "\n",
        "21. How can heteroscedasticity be identified in residual plots, and why is it\n",
        "important to address it?\n",
        " - Look for patterns in the residual plot (e.g., funnel shape).\n",
        "\n",
        " It’s important to address because it violates model assumptions and affects inference validity.\n",
        "\n",
        "22. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
        " - It may indicate that unnecessary predictors are in the model that do not contribute meaningfully and just inflate R².\n",
        "\n",
        "\n",
        "23. Why is it important to scale variables in Multiple Linear Regression?\n",
        " - To ensure that variables are on the same scale.\n",
        " Especially important for models involving regularization (like Ridge, Lasso).\n",
        "\n",
        "24. How does polynomial regression differ from linear regression?\n",
        " -  Polynomial regression models curved relationships by including higher-degree terms (e.g., X², X³), while linear regression models straight-line relationships.\n",
        "\n",
        "25. When is polynomial regression used?\n",
        " - When the relationship between the independent and dependent variable is   \n",
        "   non-linear but can be modeled by a polynomial curve.\n",
        "\n",
        "26. What is the general equation for polynomial regression?\n",
        " - Y=B0+B1X+B2X^2+...+BnX^n\n",
        "\n",
        "27. Can polynomial regression be applied to multiple variables?\n",
        " - Yes, this is known as Multivariate Polynomial Regression.\n",
        "\n",
        "28. What are the limitations of polynomial regression?\n",
        " - Prone to overfitting.\n",
        "\n",
        "   Extrapolation is unreliable.\n",
        "\n",
        "Higher degrees may make the model unstable.\n",
        "29. What methods can be used to evaluate model fit when selecting the degree of\n",
        "a polynomial?\n",
        " - Cross-validation\n",
        "\n",
        "  Adjusted R^2\n",
        "\n",
        "  AIC/BIC\n",
        "\n",
        "  Residual analysis\n",
        "\n",
        "30. Why is visualization important in polynomial regression?\n",
        " - To understand the shape of the relationship and check if the polynomial model fits the data well.\n",
        "\n",
        "31. How is polynomial regression implemented in Python?\n",
        "\n",
        "- from sklearn.preprocessing import PolynomialFeatures\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from sklearn.pipeline import make_pipeline\n",
        "\n",
        "  model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "  model.fit(X, y)\n"
      ],
      "metadata": {
        "id": "otDPltgRDgoK"
      }
    }
  ]
}